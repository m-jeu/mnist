{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part of notebook stolen from kaggle:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_time() -> str:\n",
    "    return datetime.datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "\n",
    "def log_print(inp: str) -> None:\n",
    "    # FIXME(m-jeu): Actually log in addition to printing\n",
    "    inp = f\"{current_time()}: {inp}\"\n",
    "    print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "log_print(f\"Setting device to {DEVICE} {f'named {torch.cuda.get_device_name()}' if torch.cuda.is_available() else 'with cuda not available'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from https://www.kaggle.com/code/hojjatk/read-mnist-dataset/notebook :)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Verify Reading Dataset via MnistDataloader class\n",
    "#\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path  import join\n",
    "\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = 'dataset/'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting everything to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_list_np_to_torch(data):\n",
    "    data = np.array(data)\n",
    "    data = torch.from_numpy(data)\n",
    "    return data\n",
    "\n",
    "x_test = list_list_np_to_torch(x_test)\n",
    "y_test = list_list_np_to_torch(y_test)\n",
    "x_train = list_list_np_to_torch(x_train)\n",
    "y_train = list_list_np_to_torch(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar(train_labels, train_counts, tick_label=train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, test_counts = np.unique(y_test, return_counts=True)\n",
    "plt.bar(test_labels, test_counts, tick_label=test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyClassifier()\n",
    "baseline.fit(x_train, y_train)\n",
    "baseline.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale input data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(x_train).item(), torch.max(x_train).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_float(t):\n",
    "\n",
    "    return t / 255\n",
    "\n",
    "\n",
    "x_train = scale_to_float(x_train)\n",
    "x_test = scale_to_float(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change output tensors to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = torch.nn.functional.one_hot(y_train.long())\n",
    "#i = 0\n",
    "#for o, n in zip(y_train, new):\n",
    "#    print(o)\n",
    "#    print(n)\n",
    "#    print(\"\\n\\n##############\\n\\n\")\n",
    "#    i += 1\n",
    "#    if i > 100:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_to_one_hot(t):\n",
    "    return torch.nn.functional.one_hot(t.long())\n",
    "\n",
    "y_train = y_to_one_hot(y_train)\n",
    "y_test = y_to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.double()\n",
    "y_test = y_test.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, device=DEVICE):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        if(self.images.shape[0] != self.labels.shape[0]):\n",
    "            raise ValueError(\"Amount of images and labels do not align\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx, :, :], self.labels[idx]\n",
    "    \n",
    "    def to_device(self):\n",
    "        self.images = self.images.to(self.device)\n",
    "        self.labels = self.labels.to(self.device)\n",
    "        return self\n",
    "    \n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "i, l = train_dataset.__getitem__(13456)\n",
    "plt.imshow(i, cmap=plt.cm.gray)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "batch = next(iter(dl))[0]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyLinear, self).__init__()\n",
    "\n",
    "\n",
    "        self.f = torch.nn.Flatten()\n",
    "        self.l1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28, 100),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 100),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.l3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 10),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.f(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = TinyLinear()\n",
    "f\"Amount of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(2) == torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_sum(outputs, labels):\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "    labels = labels.argmax(dim=1)\n",
    "\n",
    "    return torch.sum(outputs == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        epochs,\n",
    "        report_ever_epochs: int = 1,\n",
    "        return_lowest_test_loss_model: bool = False,\n",
    "        device = DEVICE):\n",
    "    \n",
    "    training_example_amount = len(train_loader.dataset)\n",
    "    testing_example_amount = len(test_loader.dataset)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    min_test_loss = float(\"inf\")\n",
    "    model_checkpoint = None\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc += accuracy_sum(outputs, labels).item()\n",
    "            \n",
    "        \n",
    "        train_losses.append(running_loss / training_example_amount)\n",
    "        train_acc.append(running_acc / training_example_amount)\n",
    "        \n",
    "        # Test\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            \n",
    "            for inputs, labels in test_loader:\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                running_acc += accuracy_sum(outputs, labels).item()\n",
    "\n",
    "            test_loss = running_loss / testing_example_amount\n",
    "            test_losses.append(test_loss)\n",
    "            test_acc.append(running_acc / testing_example_amount)\n",
    "\n",
    "        if (epoch % report_ever_epochs) == 0:\n",
    "            log_print(f\"{epoch}: {train_losses[-1]} | {test_losses[-1]} | {train_acc[-1]} | {test_acc[-1]}\")\n",
    "        \n",
    "        if return_lowest_test_loss_model and test_losses[-1] < min_test_loss:\n",
    "            model_checkpoint = OrderedDict({k: v.to('cpu', copy=True) for k, v in model.state_dict().items()})  # https://discuss.pytorch.org/t/copy-best-model-from-gpu-to-cpu/38683/4\n",
    "\n",
    "    if model_checkpoint is not None:\n",
    "        model.load_state_dict(model_checkpoint)\n",
    "\n",
    "    return model, pd.DataFrame({\n",
    "        \"train_loss\": train_losses,\n",
    "        \"test_loss\": test_losses,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = pathlib.Path(\"models/\")\n",
    "\n",
    "\n",
    "def train_or_load_classifier(title: str, model, *args, **kwargs):\n",
    "\n",
    "    model_folder = MODEL_FOLDER / title\n",
    "\n",
    "    if model_folder.exists():\n",
    "        log_print(f\"Loading model from {model_folder}\")\n",
    "\n",
    "        model.load_state_dict(torch.load(model_folder / \"model.pt\"))\n",
    "        model.eval()\n",
    "\n",
    "        metrics = pd.read_csv(model_folder / \"metrics.csv\", index_col=0)\n",
    "\n",
    "    else:\n",
    "        log_print(f\"Training {title} from scratch\")\n",
    "\n",
    "        model, metrics = train_classifier(model, *args, **kwargs)\n",
    "\n",
    "        log_print(f\"Saving model to {model_folder}\")\n",
    "\n",
    "        os.mkdir(model_folder)\n",
    "\n",
    "        torch.save(model.state_dict(), model_folder / \"model.pt\")\n",
    "\n",
    "        metrics.to_csv(model_folder / \"metrics.csv\")\n",
    "\n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics: pd.DataFrame) -> None:\n",
    "\n",
    "    col_amount = metrics.columns.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=col_amount // 2,  # Train / Test\n",
    "        ncols=1,\n",
    "        figsize=(15, 3 * col_amount)\n",
    "    )  \n",
    "\n",
    "    # Could clean with multiindexed column names (train/test)\n",
    "    for i, metric_name in enumerate([col_name[6:] for col_name in metrics.columns if \"train_\" in col_name]):\n",
    "        axes[i].plot(metrics[f\"train_{metric_name}\"], color=\"blue\")\n",
    "        axes[i].plot(metrics[f\"test_{metric_name}\"], color=\"red\")\n",
    "        axes[i].legend([\"Train\", \"Test\"])\n",
    "        axes[i].set_title(f\"{metric_name} per epoch\")\n",
    "        axes[i].set_xlabel(\"Epoch\")\n",
    "        axes[i].set_ylabel(f\"{metric_name}\")\n",
    "        axes[i].grid(visible=True)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyLinear()\n",
    "train_loader = DataLoader(train_dataset.to_device(), batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset.to_device(), batch_size=100, shuffle=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 200\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "model, metrics = train_or_load_classifier(\"tiny_linear\", model, train_loader, test_loader, optimizer, loss_fn, epochs, return_lowest_test_loss_model=True)\n",
    "plot_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics[\"train_loss\"].is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testacc = [item.cpu().item() for item in testacc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Amount of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyCNN, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "tiny_cnn = TinyCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
